# .github/workflows/scrape_grocery_prices.yml

name: Scrape Grocery Prices

on:
  workflow_dispatch:
    inputs:
      location_json:
        description: 'Location JSON (e.g., {"zip_code": "90210"})'
        required: true
        default: '{"zip_code": "90210", "city": "Beverly Hills"}'
      stores_config_json:
        description: 'Stores Config JSON (e.g., [{"name": "Store A", "url": "http://...", "identifier": "example_store_type_1"}])'
        required: true
        default: '[{"name": "Example Grocer", "url": "https://www.examplegrocery.com", "identifier": "example_store_type_1"}]'
      products_json:
        description: 'Products JSON (e.g., ["milk 1 gallon", "eggs dozen"])'
        required: true
        default: '["organic milk 1 gallon", "free range eggs dozen"]'
      github_repo_url:
        description: 'Target GitHub Repo URL (e.g., https://github.com/your-user/your-repo.git)'
        required: true
        default: 'https://github.com/Trapmack/ShopSmart.git' # Defaulting to ShopSmart repo
      github_branch:
        description: 'Target GitHub Branch (e.g., main or data-updates)'
        required: true
        default: 'main'
      github_file_path_prefix:
        description: 'File Path Prefix in Repo (e.g., scraped_data/daily/)'
        required: true
        default: 'scraped_prices/workflow_triggered/'
      git_user_name:
        description: 'Git User Name for Commits'
        required: true
        default: 'GitHub Actions Scraper Bot'
      git_user_email:
        description: 'Git User Email for Commits'
        required: true
        default: 'actions-bot@users.noreply.github.com'

  # schedule:
  #   - cron: '0 5 * * *' # Uncomment and adjust cron schedule as needed

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Assuming requirements.txt is in grocery_scraper_service/
          if [ -f ./grocery_scraper_service/requirements.txt ]; then pip install -r ./grocery_scraper_service/requirements.txt; fi

      - name: Run Grocery Scraper Script
        env:
          # GITHUB_PAT is a secret configured in your repository settings
          # (Settings > Secrets and variables > Actions > New repository secret)
          GH_PAT: ${{ secrets.GROCERY_SCRAPER_PAT }}
        run: |
          # Ensure the script is executable if needed: chmod +x ./grocery_scraper_service/grocery_scraper.py
          python ./grocery_scraper_service/grocery_scraper.py \
            --location_json '${{ github.event.inputs.location_json || ''{"zip_code": "00000"}'' }}' \
            --stores_config_json '${{ github.event.inputs.stores_config_json || ''[]'' }}' \
            --products_json '${{ github.event.inputs.products_json || ''[]'' }}' \
            --github_repo_url '${{ github.event.inputs.github_repo_url }}' \
            --github_pat "$GH_PAT" \
            --github_branch '${{ github.event.inputs.github_branch }}' \
            --github_file_path_prefix '${{ github.event.inputs.github_file_path_prefix }}' \
            --git_user_name '${{ github.event.inputs.git_user_name }}' \
            --git_user_email '${{ github.event.inputs.git_user_email }}'
        # Note: For scheduled runs, github.event.inputs will be empty.
        # You'd typically hardcode parameters for scheduled runs or read them from a config file
        # committed in the repository.
        # Example for scheduled run (replace inputs with actual values or config file logic):
        # if [ "${{ github.event_name }}" == "schedule" ]; then
        #   python ./grocery_scraper_service/grocery_scraper.py \
        #     --location_json '{"zip_code": "12345"}' \
        #     --stores_config_json '[{"name": "Scheduled Store", "url": "...", "identifier": "..."}]' \
        #     --products_json '["scheduled product"]' \
        #     --github_repo_url 'https://github.com/Trapmack/ShopSmart.git' \
        #     --github_pat "$GH_PAT" \
        #     --github_branch 'data-updates' \
        #     --github_file_path_prefix 'scraped_data/scheduled/' \
        #     --git_user_name 'Scheduled Scraper Bot' \
        #     --git_user_email 'actions-bot@users.noreply.github.com'
        # fi

      - name: Output commit URL (Informational)
        # The Python script already prints the GitHub URL of the committed file.
        # This step is just to show that the action completed.
        run: echo "Scraping script finished. Check script logs for the commit URL."
